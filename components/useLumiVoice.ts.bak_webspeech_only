"use client";

import { useEffect, useMemo, useRef, useState } from "react";
import { getLumiEnabled, getLumiTone, getLumiVoice } from "@/lib/lumiSettings";

export type VoiceStatus = "idle" | "speaking" | "paused";

export default function useLumiVoice() {
  const [status, setStatus] = useState<VoiceStatus>("idle");

  // Web Speech fallback
  const [voices, setVoices] = useState<SpeechSynthesisVoice[]>([]);
  const audioRef = useRef<HTMLAudioElement | null>(null);

  useEffect(() => {
    if (typeof window === "undefined") return;
    audioRef.current = new Audio();
    audioRef.current.preload = "auto";
    return () => {
      audioRef.current?.pause();
      audioRef.current = null;
    };
  }, []);

  useEffect(() => {
    if (typeof window === "undefined" || !("speechSynthesis" in window)) return;

    const load = () => {
      setVoices(window.speechSynthesis.getVoices());
    };

    load();
    window.speechSynthesis.onvoiceschanged = load;

    return () => {
      window.speechSynthesis.onvoiceschanged = null;
    };
  }, []);

  const bestVoice = useMemo(() => {
    if (!voices.length) return null;

    const preferred = ["Samantha", "Ava", "Victoria", "Allison", "Google US English"];
    const avoid = /robot|zira|fred|male|compact/i;

    const candidates = voices
      .filter((v) => v.lang?.startsWith("en"))
      .filter((v) => !avoid.test(v.name))
      .sort((a, b) => Number(b.localService) - Number(a.localService));

    for (const name of preferred) {
      const found = candidates.find((v) => v.name === name);
      if (found) return found;
    }
    return candidates[0] || voices[0];
  }, [voices]);

  function stop() {
    if (typeof window === "undefined") return;

    if (audioRef.current) {
      audioRef.current.pause();
      audioRef.current.currentTime = 0;
    }

    if ("speechSynthesis" in window) {
      window.speechSynthesis.cancel();
    }

    setStatus("idle");
  }

  async function speak(text: string) {
    // Respect user's preference
    if (!getLumiEnabled()) return;
    if (typeof window === "undefined") return;
    if (!text?.trim()) return;

    stop();
    setStatus("speaking");

    // If you already have /api/tts wired, this will use it.
    // If not, it falls back to Web Speech.
    try {
      const tone = getLumiTone();
      const voice = getLumiVoice();

      const instructions =
        tone === "playful"
          ? "Warm, playful, lightly teasing dating coach. Natural pacing. Not robotic."
          : tone === "serious"
          ? "Warm, calm, serious dating coach. Clear pauses. Not robotic."
          : "Warm, calm, emotionally intelligent dating coach. Gentle pauses. Not robotic.";

      const r = await fetch("/api/tts", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ text, voice, format: "mp3", instructions }),
      });

      if (!r.ok) throw new Error(await r.text());

      const blob = await r.blob();
      const url = URL.createObjectURL(blob);

      const a = audioRef.current;
      if (!a) throw new Error("No audio element");

      a.src = url;

      a.onended = () => {
        URL.revokeObjectURL(url);
        setStatus("idle");
      };

      a.onerror = () => {
        URL.revokeObjectURL(url);
        setStatus("idle");
      };

      await a.play();
      return;
    } catch {
      // fallback to Web Speech
    }

    if (!("speechSynthesis" in window)) {
      setStatus("idle");
      return;
    }

    const u = new SpeechSynthesisUtterance(text);
    if (bestVoice) u.voice = bestVoice;
    u.rate = 0.92;
    u.pitch = 1.06;
    u.volume = 1;

    u.onend = () => setStatus("idle");
    u.onerror = () => setStatus("idle");

    window.speechSynthesis.speak(u);
  }

  function pause() {
    if (typeof window === "undefined") return;

    if (audioRef.current && !audioRef.current.paused) {
      audioRef.current.pause();
      setStatus("paused");
      return;
    }

    if ("speechSynthesis" in window) {
      window.speechSynthesis.pause();
      setStatus("paused");
    }
  }

  function resume() {
    if (typeof window === "undefined") return;

    if (audioRef.current && audioRef.current.paused && audioRef.current.currentTime > 0) {
      audioRef.current.play();
      setStatus("speaking");
      return;
    }

    if ("speechSynthesis" in window) {
      window.speechSynthesis.resume();
      setStatus("speaking");
    }
  }

  return {
    supported: true,
    status,
    isSpeaking: status === "speaking",
    speak,
    stop,
    pause,
    resume,
    voiceName: `pref:${getLumiVoice()}`,
  };
}
